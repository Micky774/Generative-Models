Experiment Log
==============

Corresponding to tb runs/obs5, experimenting with pseudoinput learning rates as which are the cartesian product of
pl([1,4,7]x[e-5,e-6,e-7]) corresponding to designation [1,4,7]x[e5,e6,e7]. Experiment is run for 30 epochs at lsdim 16, pseudos 25, 
batch-size 50, global lr 1e-3

Result: Lowest loss came from plr 4d-6, however the failure to converge (nan error) for the adjacent plr (7e-6,1e-6) suggests that plr > 1e-6 isn't incredibly stable.
Hence, the ideal plr from experiment is second-lowest loss, achieved by plr 7e-7
